# -*- coding: utf-8 -*-
"""CropRecommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-ENJHKPiqxDxPtYQ_Mch91styGOXXWbW
"""

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

import matplotlib.pyplot as plt
import seaborn as sns

crop = pd.read_csv("Crop_recommendation.csv")
crop.head()

crop_dict = {
    'rice': 1, 'maize': 2, 'jute': 3, 'cotton': 4, 'coconut': 5,
    'papaya': 6, 'orange': 7, 'apple': 8, 'muskmelon': 9,
    'watermelon': 10, 'grapes': 11, 'mango': 12, 'banana': 13,
    'pomegranate': 14, 'lentil': 15, 'blackgram': 16,
    'mungbean': 17, 'mothbeans': 18, 'pigeonpeas': 19,
    'kidneybeans': 20, 'chickpea': 21, 'coffee': 22
}

crop["label"] = crop["label"].map(crop_dict)
crop.isnull().sum()

X = crop.drop("label", axis=1)
y = crop["label"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

mx = MinMaxScaler()
sc = StandardScaler()

X_train_scaled = sc.fit_transform(mx.fit_transform(X_train))
X_test_scaled = sc.transform(mx.transform(X_test))

model = RandomForestClassifier(
    n_estimators=200,
    random_state=42,
    n_jobs=-1
)

model.fit(X_train_scaled, y_train)

y_pred = model.predict(X_test_scaled)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

reverse_crop_dict = {v: k for k, v in crop_dict.items()}

def recommend_crop_top3(N, P, K, temperature, humidity, ph, rainfall):
    features = np.array([[N, P, K, temperature, humidity, ph, rainfall]])
    scaled = sc.transform(mx.transform(features))

    probs = model.predict_proba(scaled)[0]
    top3_idx = np.argsort(probs)[-3:][::-1]

    crops = [reverse_crop_dict[i + 1] for i in top3_idx]
    confidences = [round(probs[i] * 100, 2) for i in top3_idx]

    return list(zip(crops, confidences))



"""TEST:


"""

# Pick a random test sample
idx = np.random.randint(0, len(X_test))

sample = X_test.iloc[idx]
true_label = y_test.iloc[idx]

prediction = recommend_crop_top3(
    sample["N"],
    sample["P"],
    sample["K"],
    sample["temperature"],
    sample["humidity"],
    sample["ph"],
    sample["rainfall"]
)

print("True crop:", reverse_crop_dict[true_label])
print("Top-3 prediction:", prediction)

import pickle
from google.colab import files

# 1. Create a dictionary to hold everything
# We save the model, both scalers, and your label mapping
data_to_save = {
    "model": model,
    "sc": sc,
    "mx": mx,
    "arch": "rf_crop_recommendation", # Optional: metadata
}

# 2. Save it as a pickle file
filename = 'crop_recommendation.pkl'
with open(filename, 'wb') as file:
    pickle.dump(data_to_save, file)

# 3. Download it to your computer
files.download(filename)