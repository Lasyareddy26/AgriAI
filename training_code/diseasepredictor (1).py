# -*- coding: utf-8 -*-
"""DiseasePredictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yMuEk2f8gpTGSCKq8G2DO4P7FAVx4NsB
"""

!wget https://github.com/spMohanty/PlantVillage-Dataset/archive/refs/heads/master.zip
!unzip -q master.zip

import os
import torch
import torchvision
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
import torchvision.transforms as tt


# 2. Define data directory
data_dir = 'PlantVillage-Dataset-master/raw/color'

# 3. Image Transformations
# We resize to 256x256 and convert to Tensors
stats = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
train_tfms = tt.Compose([tt.Resize((256, 256)), tt.ToTensor(), tt.Normalize(*stats)])

# 4. Load dataset
dataset = ImageFolder(data_dir, train_tfms)
train_dl = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)

print(f"Found {len(dataset)} images and {len(dataset.classes)} classes.")



import torch.nn as nn

def conv_block(in_ch, out_ch, pool=False):
    layers = [nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),
              nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True)]
    if pool: layers.append(nn.MaxPool2d(2))
    return nn.Sequential(*layers)

class ResNet9(nn.Module):
    def __init__(self, in_channels, num_classes):
        super().__init__()

        self.conv1 = conv_block(in_channels, 64)
        self.conv2 = conv_block(64, 128, pool=True) # 256 -> 128
        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))

        self.conv3 = conv_block(128, 256, pool=True) # 128 -> 64
        self.conv4 = conv_block(256, 512, pool=True) # 64 -> 32
        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))

        # CHANGED: The input to Linear is now 512 * 32 * 32 (if using 256x256 input)
        # However, a better way is to use AdaptiveAvgPool2d to force a specific size
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)), # This shrinks any size to 1x1
            nn.Flatten(),
            nn.Dropout(0.2),
            nn.Linear(512, num_classes) # Now 512 matches perfectly!
        )

    def forward(self, xb):
        out = self.conv1(xb)
        out = self.conv2(out)
        out = self.res1(out) + out
        out = self.conv3(out)
        out = self.conv4(out)
        out = self.res2(out) + out
        return self.classifier(out)

# Initialize model for GPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = ResNet9(3, len(dataset.classes)).to(device)

import torch
import gc

# Clear memory
model = None
gc.collect()
torch.cuda.empty_cache()

# Optional: If the error persists, go to the top menu:
# Runtime -> Restart Session

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
import torchvision.transforms as tt

# 1. Setup Data with smaller images and small batch size
stats = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
train_tfms = tt.Compose([tt.Resize((128, 128)), tt.ToTensor(), tt.Normalize(*stats)])

# Use the directory from the earlier unzip command
data_dir = 'PlantVillage-Dataset-master/raw/color'
dataset = ImageFolder(data_dir, train_tfms)
train_dl = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2, pin_memory=True)

# 2. Re-define the Brain (Ensure the AdaptiveAvgPool2d fix is included)
class ResNet9(nn.Module):
    def __init__(self, in_channels, num_classes):
        super().__init__()
        self.conv1 = conv_block(in_channels, 64)
        self.conv2 = conv_block(64, 128, pool=True)
        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))
        self.conv3 = conv_block(128, 256, pool=True)
        self.conv4 = conv_block(256, 512, pool=True)
        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))
        self.classifier = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)), nn.Flatten(), nn.Linear(512, num_classes))

    def forward(self, xb):
        out = self.conv1(xb); out = self.conv2(out); out = self.res1(out) + out
        out = self.conv3(out); out = self.conv4(out); out = self.res2(out) + out
        return self.classifier(out)

def conv_block(in_ch, out_ch, pool=False):
    layers = [nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True)]
    if pool: layers.append(nn.MaxPool2d(2))
    return nn.Sequential(*layers)

# 3. Initialize and Train
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = ResNet9(3, len(dataset.classes)).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

print("Starting memory-efficient training...")
model.train()
for epoch in range(3): # Let's start with 3 epochs
    total_loss = 0
    for i, (images, labels) in enumerate(train_dl):
        images, labels = images.to(device), labels.to(device)

        outputs = model(images)
        loss = F.cross_entropy(outputs, labels)

        loss.backward()

        # Update weights
        optimizer.step()
        optimizer.zero_grad()

        if i % 100 == 0:
            print(f"Batch {i} done...")

    print(f"Epoch {epoch+1} Complete.")

torch.save(model.state_dict(), 'plant_disease_model.pth')

print(dataset.classes)

import torch
from PIL import Image
import torchvision.transforms as tt

def predict_image(img_path, model, dataset_classes):
    # 1. Same transformations as training (64x64)
    stats = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
    transform = tt.Compose([
        tt.Resize((64, 64)),
        tt.ToTensor(),
        tt.Normalize(*stats)
    ])

    # 2. Load and transform the image
    img = Image.open(img_path).convert('RGB')
    img_tensor = transform(img).unsqueeze(0) # Add batch dimension

    # 3. Move to GPU if available
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    img_tensor = img_tensor.to(device)
    model.to(device)

    # 4. Predict
    model.eval()
    with torch.no_grad():
        output = model(img_tensor)
        # Convert output scores to probabilities
        probs = torch.nn.functional.softmax(output, dim=1)
        conf, preds = torch.max(probs, dim=1)

    return dataset_classes[preds[0].item()], conf.item()

from google.colab import files

# Upload an image from your computer
print("Please upload a leaf image to test:")
uploaded = files.upload()
test_image_name = list(uploaded.keys())[0]

# Get the class names from your dataset
class_names = dataset.classes

# Run the prediction
label, confidence = predict_image(test_image_name, model, class_names)

print("-" * 30)
print(f"PREDICTION: {label}")
print(f"CONFIDENCE: {confidence * 100:.2f}%")
print("-" * 30)

# Show the image
import matplotlib.pyplot as plt
img = Image.open(test_image_name)
plt.imshow(img)
plt.title(f"Predicted: {label}")
plt.axis('off')
plt.show()